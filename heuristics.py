import sys
import util
from node import Node
from state import State

def applicable(state, actions):
    ''' Return a list of applicable actions in a given `state`. '''
    app = list()
    for act in actions:
        if State(state).intersect(act.precond) == act.precond:
            app.append(act)
    return app

def successorRelaxed(state, action):
    ''' Return the sucessor state generated by executing `action` in `state`. '''
    return State(action.pos_effect).union(state)

def layerGoals(state, predicates):
    return State(state).union(predicates)

def goal_test(state, goal):
    ''' Return true if `state` is a goal state. '''
    return State(state).intersect(goal) == State(goal)

def h_naive(state, planning):
    return 0

def h_add_planner(state, planning, goal):
    h = dict() 
    actions = planning.actions
    X = state
    for x in X:
        h[x] = 0
    change = True
    while change:
        change = False
        actionsApplicable = applicable(X,actions)
        for a in actionsApplicable:
            X = successorRelaxed(X,a) #added positive effects of a
            for p in a.pos_effect:
                prev = h.get(p,sys.maxsize)
                h[p] = min(prev,(1+sum(h.get(pre, sys.maxsize) for pre in a.precond)))
                if prev != h[p]:
                    change = True
    return sum(h.get(i,sys.maxsize) for i in goal)

# heuristica usada nos testes brucutu e local...estava dando bons resultados 
# def h_add(planning, state):
#     h = dict() 
#     actions = planning.actions
#     init = planning.problem.init
#     X = init
#     for x in X:
#         h[x] = 0
#     change = True
#     while change:
#         change = False
#         actionsApplicable = applicable(X,actions)
#         for a in actionsApplicable:
#             X = successorRelaxed(X,a) #added positive effects of a
#             for p in a.pos_effect:
#                 prev = h.get(p,sys.maxsize)
#                 h[p] = min(prev,(1+sum(h.get(pre, sys.maxsize) for pre in a.precond)))
#                 if prev != h[p]:
#                     change = True
#     '''
#     selecting only atoms that belongs to state
#     node_dict = {p:h.get(p,sys.maxsize) for p in state} 
#     return node_dict
#     '''
#     return h
#     #return sum(h.get(i,sys.maxsize) for i in goal)

def h_add(planning, state):
    h = dict() 
    actions = planning.actions
    #init = planning.problem.init
    X = state
    for x in X:
        h[x] = 0
    change = True
    while change:
        change = False
        actionsApplicable = applicable(X,actions)
        for a in actionsApplicable:
            X = successorRelaxed(X,a) #added positive effects of a
            for p in a.pos_effect:
                prev = h.get(p,sys.maxsize)
                h[p] = min(prev,(1+sum(h.get(pre, sys.maxsize) for pre in a.precond)))
                if prev != h[p]:
                    change = True
    '''
    selecting only atoms that belongs to state
    node_dict = {p:h.get(p,sys.maxsize) for p in state} 
    return node_dict
    '''
    return h
    #return sum(h.get(i,sys.maxsize) for i in goal)
